{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, social media posts, and product descriptions. This can help businesses reduce content creation costs and improve consistency.\n",
      "2. **Image and Video Editing**: Generative AI-powered tools can edit images and videos to create realistic effects, remove blemishes, or even generate new images from existing ones.\n",
      "3. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can respond to customer inquiries and provide personalized support.\n",
      "4. **Product Design**: Generative AI can assist in designing products by generating 2D and 3D models, providing suggestions for product development, and even creating prototypes.\n",
      "5. **Marketing Campaigns**: Generative AI can help businesses create targeted marketing campaigns by analyzing customer data and behavior to generate personalized messages and offers.\n",
      "6. **Financial Analysis**: Generative AI can analyze financial data to identify trends, predict stock prices, and provide insights for investment decisions.\n",
      "7. **Language Translation**: Generative AI-powered tools can translate languages in real-time, making it easier for businesses to communicate with global customers.\n",
      "8. **Supply Chain Optimization**: Generative AI can analyze supply chain data to optimize inventory levels, reduce costs, and improve delivery times.\n",
      "9. **Predictive Maintenance**: Generative AI can analyze sensor data from machines to predict when maintenance is required, reducing downtime and improving overall efficiency.\n",
      "10. **Cybersecurity**: Generative AI can help detect and respond to cyber threats by analyzing network traffic and identifying potential vulnerabilities.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Automated Writing Assistant**: A tool that uses Generative AI to assist writers in creating high-quality content, such as articles, blog posts, or social media updates.\n",
      "* **Personalized Product Recommendations**: An e-commerce platform that uses Generative AI to provide personalized product recommendations based on customer behavior and preferences.\n",
      "* **Chatbot for Customer Support**: A chatbot that uses Generative AI to respond to customer inquiries and provide support, reducing the need for human customer support agents.\n",
      "* **Automated Content Calendar**: A tool that uses Generative AI to generate a content calendar for businesses, ensuring consistency and efficiency in content creation.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more, saving time and resources for content creators.\n",
      "2. **Marketing Automation**: AI-powered generative tools can create personalized marketing messages, emails, and ad copy, helping businesses personalize their marketing efforts and improve ROI.\n",
      "3. **Customer Service Chatbots**: Generative AI enables the creation of highly realistic chatbots that can engage with customers, answer questions, and provide support, reducing the need for human customer service agents.\n",
      "4. **Product Design and Development**: AI-powered generative tools can design new products, such as furniture, buildings, or electronic devices, based on user input, trends, and market demand.\n",
      "5. **Finance and Accounting**: Generative AI can automate tasks such as financial forecasting, tax preparation, and accounting bookkeeping, freeing up human resources for more strategic work.\n",
      "6. **Human Resources**: AI-powered generative tools can create personalized employee onboarding materials, performance evaluations, and career development plans, improving the overall HR experience.\n",
      "7. **Supply Chain Optimization**: Generative AI can analyze market trends, demand patterns, and logistics data to optimize supply chain operations, predict demand, and reduce costs.\n",
      "8. **Data Science and Analytics**: Generative AI can help with data visualization, pattern recognition, and predictive modeling, providing insights that inform business decisions.\n",
      "9. **Music and Audio Production**: Generative AI can create new music, sound effects, and audio tracks, opening up new creative possibilities for music producers and composers.\n",
      "10. **Healthcare**: Generative AI can aid in medical diagnosis, patient data analysis, and personalized medicine by generating new treatment options and predicting disease outcomes.\n",
      "\n",
      "Some notable business applications of Generative AI include:\n",
      "\n",
      "* **Google's Bard**: A conversational AI tool that generates human-like text responses to user input.\n",
      "* **Microsoft's Azure Machine Learning**: A cloud-based platform for building, training, and deploying machine learning models, including generative AI models.\n",
      "* **Adobe Fresco**: An AI-powered drawing and painting app that uses generative AI to create realistic brushstrokes and textures.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054baa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a process engineer with a robotics background trying to improve the process and \n",
    "movement of the machine by gathering process sensor data and evaluating it into markdown.\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "    i am encountering critical fft peaks at around 540 Hz and a process speed of 5600RPM. the process seems to cause issues on the resulting part,\n",
    "    what parts should i check regarding damages and how should i go about solving my issue. try to compose a mathematical or analytical solution by \n",
    "    completing order analysis and potential part groups fitting that order\n",
    "\"\"\"\n",
    "\n",
    "def llm_dict_from(system_prompt, user_prompt):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "def summarize():\n",
    "    response = ollama.chat(\n",
    "        model = 'llama3.2-vision',\n",
    "        messages = llm_dict_from(system_prompt, user_prompt)\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "def display_process_analysis():\n",
    "    summary = summarize()\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_process_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60198ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import markdown2\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Initialize the Anthropic client (you'll need to set your API key)\n",
    "load_dotenv()\n",
    "client = Anthropic(api_key=os.getenv('CLAUDE_API_KEY'))\n",
    "\n",
    "# Create the system and user prompts\n",
    "system_prompt = \"\"\"You are a process engineer with a robotics background trying to improve the process and\n",
    "movement of the machine by gathering process sensor data and evaluating it into markdown.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    i am encountering critical fft peaks at around 540 Hz and a process speed of 5600RPM. the process seems to cause issues on the resulting part,\n",
    "    what parts should i check regarding damages and how should i go about solving my issue. try to compose a mathematical or analytical solution by\n",
    "    completing order analysis and potential part groups fitting that order\n",
    "\"\"\"\n",
    "\n",
    "def create_claude_messages(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Prepare messages for Claude API in the required format.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): The system context for the analysis\n",
    "        user_prompt (str): The specific user query or problem description\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of message dictionaries formatted for the Claude API\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "def analyze_process():\n",
    "    \"\"\"\n",
    "    Send the prompts to Claude and retrieve the analysis.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated markdown-formatted analysis response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the messages\n",
    "        messages = create_claude_messages(system_prompt, user_prompt)\n",
    "        \n",
    "        # Call the Claude API\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",  # You can choose a different model if preferred\n",
    "            max_tokens=1000,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # Extract the content from the response\n",
    "        return response.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def display_process_analysis():\n",
    "    \"\"\"\n",
    "    Analyze the process and display the result as formatted markdown.\n",
    "    \"\"\"\n",
    "    # Get the analysis\n",
    "    summary = analyze_process()\n",
    "    \n",
    "    # Convert to HTML (optional, depends on your display method)\n",
    "    html_summary = markdown2.markdown(summary)\n",
    "    \n",
    "    # Display method depends on your environment \n",
    "    # For Jupyter:\n",
    "    # from IPython.display import display, HTML\n",
    "    # display(HTML(html_summary))\n",
    "    \n",
    "    # For standard output:\n",
    "    print(summary)\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    display_process_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499582b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
